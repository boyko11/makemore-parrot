{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a85b7f9",
   "metadata": {},
   "source": [
    "### Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ceb16e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5865b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min([len(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876920f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max([len(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just figuring out what zip does for uneven lists\n",
    "for one, two in zip([1, 2, 3], [2, 3]):\n",
    "    print( one, two)\n",
    "print('-')\n",
    "for one, two in zip([1, 2], [1, 2, 3]):\n",
    "    print( one, two)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how can zip help us in creating bigrams\n",
    "bigram_counts = {}\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    # print(chs)\n",
    "    for c1, c2 in zip(chs, chs[1:]):\n",
    "        bigram = (c1, c2)\n",
    "        bigram_counts[bigram] = bigram_counts.get(bigram, 0) + 1\n",
    "        # print(c1, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7082cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_sorted_by_value = sorted(bigram_counts, key=bigram_counts.get, reverse=True)\n",
    "for bigram in bigrams_sorted_by_value:\n",
    "    print(bigram, bigram_counts[bigram])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4ba937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d579c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BIGRAM_COUNTS = torch.ones((27, 27), dtype=torch.int32)\n",
    "# ones instead of zeros to avoid 0 probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56000f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps from string(character) to int index and vice versa - from int index to string(char) \n",
    "chars = sorted(list(set(''.join(words))))\n",
    "chars.insert(0, '.')\n",
    "stoi = {s: i for i, s in enumerate(chars)}\n",
    "itos = {i: s for i, s in enumerate(chars)}\n",
    "print(stoi)\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e3f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    # print(chs)\n",
    "    for c1, c2 in zip(chs, chs[1:]):\n",
    "        c1_idx = stoi[c1]\n",
    "        c2_idx = stoi[c2]\n",
    "        BIGRAM_COUNTS[c1_idx, c2_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIGRAM_COUNTS[stoi['n'], stoi['.']]\n",
    "BIGRAM_COUNTS.size(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b49fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.imshow(BIGRAM_COUNTS, cmap='Blues')\n",
    "for i in range(BIGRAM_COUNTS.size(dim=0)):\n",
    "    for j in range(BIGRAM_COUNTS.size(dim=1)):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        plt.text(j, i, chstr, ha='center', va='bottom', color='gray')\n",
    "        plt.text(j, i, BIGRAM_COUNTS[i, j].item(), ha='center', va='top', color='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e986fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "p = torch.rand(3, generator=g)\n",
    "p\n",
    "p = p/p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b4b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.multinomial(p, num_samples=100, replacement=True, generator=g).numpy()\n",
    "print(results)\n",
    "from collections import Counter\n",
    "Counter(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = BIGRAM_COUNTS[0,:]/sum(BIGRAM_COUNTS[0,:])\n",
    "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "ix\n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190126a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = BIGRAM_COUNTS/BIGRAM_COUNTS.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e1e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    generated_word = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "#         row_for_index = BIGRAM_COUNTS[ix, :].float()\n",
    "#         p = row_for_index/row_for_index.sum()\n",
    "        ix = torch.multinomial(P[ix, :], num_samples=1, replacement=True, generator=g).item()\n",
    "        sampled_char = itos[ix]\n",
    "        generated_word.append(sampled_char)\n",
    "        if sampled_char == '.':\n",
    "            break\n",
    "\n",
    "    print(''.join(generated_word))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Maximize Likelihood of the data w.r.t the model parameters (statistical modeling)\n",
    "# equivalent to maximizing the log likelihood (because log is monotonic)\n",
    "# equivalent to minimizing the negative log likelihood\n",
    "# equivalent to minimizing the mean negative log likelihood\n",
    "\n",
    "# log(a*b*c) = log(a) + log(b) + log(c)\n",
    "\n",
    "log_likelihood = 0.0\n",
    "num_bigrams = 0\n",
    "for w in words:\n",
    "#for w in [\"bkoyko\"]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    # print(chs)\n",
    "    for c1, c2 in zip(chs, chs[1:]):\n",
    "        c1_idx = stoi[c1]\n",
    "        c2_idx = stoi[c2]\n",
    "        prob = P[c1_idx, c2_idx]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        print(f'{c1}{c2}: {prob:.4f} {logprob:.4f}')\n",
    "        num_bigrams += 1\n",
    "        \n",
    "print(f'{log_likelihood=}')\n",
    "neg_log_likelihood = - log_likelihood\n",
    "print(f'{neg_log_likelihood=}')\n",
    "mean_neg_log_likelihood = neg_log_likelihood/num_bigrams\n",
    "print(f'{mean_neg_log_likelihood=}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae48e1d",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44d744",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create a training set of bigrams(x, y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for c1, c2 in zip(chs, chs[1:]):\n",
    "        c1_idx = stoi[c1]\n",
    "        c2_idx = stoi[c2]\n",
    "        xs.append(c1_idx)\n",
    "        ys.append(c2_idx)\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d95c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "x_enc = F.one_hot(xs, num_classes=27).float()\n",
    "x_enc.shape\n",
    "y_enc = F.one_hot(xs, num_classes=27).float()\n",
    "plt.imshow(x_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d57db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly initialize 27 neurons' weights, each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
    "W.shape, x_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1e77bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward pass\n",
    "x_enc = F.one_hot(xs, num_classes=27).float() # input to the network - one-hot encoded character\n",
    "logits = x_enc @ W # predict log counts\n",
    "counts = logits.exp() # counts equivalent to BIGRAM_COUNTS\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "# above two lines are 'softmax'\n",
    "loss = (-(probs[torch.arange(5), ys].log())).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e74cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nll = negative log likelihood\n",
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "    # the i-th bigram\n",
    "    x = xs[i].item() # input character index\n",
    "    y = ys[i].item() # label character index\n",
    "    print('----')\n",
    "    print(f'bigram example {i+1}: {itos[x]}{itos[y]} indexes({x},{y})')\n",
    "    print('input to the Nerual Net: ', x)\n",
    "    print('output probabilities from the neural net: ', probs[i])\n",
    "    print('label(actual next character index): ', y)\n",
    "    p = probs[i, y]\n",
    "    print('Probability assigned by the neural net to the correct charatecter: ', p.item())\n",
    "    logp = torch.log(p)\n",
    "    print('log likelihood: ', logp)\n",
    "    nll = -logp\n",
    "    print('negative log likelihood: ', nll)\n",
    "    nlls[i] = nll\n",
    "    \n",
    "print('========')\n",
    "print('average negative log likelihood, i.e. loss = ', nlls.mean().item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0876838",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f06a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a5286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[0, 5], probs[1, 13], probs[2, 13], probs[3, 1], probs[4, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c66c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (-(probs[torch.arange(5), ys].log())).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None # sets the gradient to Zero\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc24120",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d26fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update weights\n",
    "W.data -= 0.1 * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df5ba06",
   "metadata": {},
   "source": [
    "##### Let's put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "9061ee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for c1, c2 in zip(chs, chs[1:]):\n",
    "        c1_idx = stoi[c1]\n",
    "        c2_idx = stoi[c2]\n",
    "        xs.append(c1_idx)\n",
    "        ys.append(c2_idx)\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "\n",
    "print(\"Number of examples: \", num)\n",
    "\n",
    "# initialize the network\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "453a2fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.768618583679199\n",
      "2.719987630844116\n",
      "2.596351146697998\n",
      "2.5505459308624268\n",
      "2.5276565551757812\n",
      "2.514451503753662\n",
      "2.506150484085083\n",
      "2.500559091567993\n",
      "2.4965858459472656\n",
      "2.493650197982788\n",
      "2.491422414779663\n",
      "2.489698886871338\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(100):\n",
    "    \n",
    "    #forward pass\n",
    "    x_enc = F.one_hot(xs, num_classes=27).float() # input to the network - one-hot encoded character\n",
    "    logits = x_enc @ W # predict log counts\n",
    "    counts = logits.exp() # counts equivalent to BIGRAM_COUNTS\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    loss = (-(probs[torch.arange(num), ys].log())).mean()\n",
    "    # regularization\n",
    "    reg_lambda = 0.01\n",
    "    loss += reg_lambda * (W**2).mean().item()\n",
    "    if k % 9 == 0:\n",
    "        print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None # sets the gradient to Zero\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update weights\n",
    "    learning_rate = 50\n",
    "    W.data -= learning_rate * W.grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "9c1f4a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mor.\n",
      "axwaninaymoryles.\n",
      "kondmaisah.\n",
      "anchshizarie.\n",
      "odaren.\n"
     ]
    }
   ],
   "source": [
    "# sample form the neural net\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    sampled_word = []\n",
    "    ix = 0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        # BEFORE\n",
    "        # p = P[ix]\n",
    "        \n",
    "        # NOW\n",
    "        x_enc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = x_enc @ W # predict log counts\n",
    "        counts = logits.exp() # counts equivalent to BIGRAM_COUNTS\n",
    "        p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "        \n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        sampled_char = itos[ix]\n",
    "        sampled_word.append(sampled_char)\n",
    "        if sampled_char == '.':\n",
    "            break\n",
    "     \n",
    "    print(''.join(sampled_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a76894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mor.\n",
    "axx.\n",
    "minaymoryles.\n",
    "kondlaisah.\n",
    "anchshizarie."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
